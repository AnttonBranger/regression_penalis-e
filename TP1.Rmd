---
title: "TP1"
author: "Antton Branger"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
rm(list = ls())
```

Chargement des packages

```{r, include=FALSE}
library(tidyverse)
library(glmnet)
```

# Prise en charge du jeu de données

Importation des données

```{r}
breast_cancer <- read.table("breast_cancer.txt", header = T)
```

Détaction des valeurs manquantes

```{r}
all(is.na(breast_cancer))
```

Séparations du jeux de données en deux : la variable à expliquer et les variables explicatives

```{r}
Y <- as.numeric(breast_cancer[,1])
X <- as.matrix(breast_cancer[,-1])
rm(breast_cancer)
```

Nombre de patients et nombre de variables explicatives

```{r}
n <- length(Y)
p <- ncol(X)
```

Distribution de Y

```{r}
summary(Y)
```

Distribution des variables explicatives

```{r}
summary(apply(X, 2, mean))
```

Distribution des écarts-types des variables explicatives

```{r}
summary(apply(X, 2, sd))
```

On centre la variable y

```{r}
Y <- scale(Y, center = T, scale = F)
```

On centre et réduit les colonnes de X à l'aide de la fonction scale

```{r}
X <- scale(X, center = T, scale = T)
```

# Analyse univariée

$$ \hat{\beta} = (X^TX)^{-1}X^TY $$ 

Calcul du vecteur composé des p estimateurs des écarts types
```{r}
beta.uni <- as.vector((t(X) %*% Y)/(n - 1))
```

Vecteur des estimateurs des écarts-types de coefficients $$ \hat{\beta_1^u}, ... , \hat{\beta_p^u}$$
```{r}
sigma2.uni <- colSums((matrix(rep(Y, ncol(X)), nrow = n, byrow = F) - t(t(X) * beta.uni))**2)/(n - 2)
se <- sqrt(sigma2.uni)
```

Vérification avec la fonction lm()
```{r}
i = 10625
summary(lm(Y ~ X[,i]))$coefficients[2, 1:2]
beta.uni[i]
se[i]
```

Calculer les p-value
```{r}
pval <- pchisq( (beta.uni/se)**2, df = 1, lower = F)
qqplot(-log10(ppoints(p)), -log10(pval), pch = 4)
abline(0, 1)
```

# Régressions LASSO et elasticnet de la librairie glmnet

## Regression LASSO 

Validation croisée à 5 fold pour choisir le meilleur modèle de regression LASSO
```{r}
cv_lasso <- cv.glmnet(X, Y, alpha = 1, nfolds = 5)
plot(cv_lasso)
```
Nombre de lambda testé
```{r}
length(cv_lasso)
```


```{r}
plot(cv_lasso$glmnet.fit, xvar = "lambda")
abline(v = log(cv_lasso$lambda.min), lty = 2)
abline(v = log(cv_lasso$lambda.1se), lty = 2)
```
Fillamment correspond à un coefficient

Affichage du nom des gènes sélectionnés et de leur p-value correspondante
```{r}
lasso_var <- as.matrix(coef(cv_lasso, s = "lambda.min"))
lasso_var1 <- as.matrix(cv_lasso$glmnet.fit$beta[,which(cv_lasso$lamda == cv_lasso$lambda.min)])
all(lasso_var[-1,] == lasso_var1)

genes <- names(which(abs(lasso_var[,1]) > 1e-10))
lasso_ind <- which(abs(lasso_var[,1]) > 1e-10) - 1
data.frame(gene = genes, beta = beta.uni[lasso_ind], se = se[lasso_ind], pval = pval[lasso_ind])
```


## Regression elasticnet

Validation croisée à 5 fold pour choisir le meilleur modèle de regression elasticnet
```{r}
cverror <- rep(NA, 11)
for(j in 0:10){
  fit <- cv.glmnet(X, Y, alpha = (j/10))
  cverror[j+1] <- min(cv_lasso$cvm)
  assign(paste("fit_", j, sep = ""), fit)
}
which.min(cverror) 
```
RIDGE l'emporte car si on enlève 1 on arrive à 0

```{r}
plot(cv_elasticnet$glmnet.fit, xvar = "lambda")
abline(v = log(cv_elasticnet$lambda.min), lty = 2)
abline(v = log(cv_elasticnet$lambda.1se), lty = 2)
```

Affichage du nom des gènes sélectionnés et de leur p-value correspondante
```{r}
elasticnet_var <- as.matrix(coef(cv_elasticnet, s = "lambda.min"))
elasticnet_var1 <- as.matrix(cv_elasticnet$glmnet.fit$beta[,which(cv_elasticnet$lamda == cv_elasticnet$lambda.min)])
all(elasticnet_var[-1,] == elasticnet_var1)

genes <- names(which(abs(elasticnet_var[,1]) > 1e-10))
elasticnet_ind <- which(abs(elasticnet_var[,1]) > 1e-10) - 1
data.frame(gene = genes, beta = beta.uni[elasticnet_ind], se = se[elasticnet_ind], pval = pval[elasticnet_ind])
length(genes)
sum(pval < 1e-7)
```

## Choix optimale du alpha

